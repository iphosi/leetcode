{"root":{"data":{"id":"d4edzqcc4340","created":1727168097619,"text":"RAG"},"children":[{"data":{"id":"d4f6cmfaqo00","created":1727248098903,"text":"评测","layout_mind_offset":{"x":109,"y":-500}},"children":[{"data":{"id":"d4edzzf0nmo0","created":1727168117373,"text":"RAGAs","layout_mind_offset":{"x":28,"y":-241}},"children":[{"data":{"id":"d4ee1hhlffc0","created":1727168235075,"text":"忠实度 (Faithfulness)","layout_right_offset":{"x":16,"y":4}},"children":[{"data":{"id":"d4ee3cmwwk00","created":1727168381241,"text":"衡量生成的答案 (answer) 与给定上下文 (context) 的事实一致性","layout_right_offset":{"x":7,"y":-2}},"children":[]},{"data":{"id":"d4ee95lvxmg0","created":1727168836126,"text":"如果答案 (answer) 中提出的所有基本事实 (claims) 都可以从给定的上下文 (context) 中推断出来，则生成的答案被认为是忠实的"},"children":[]}]},{"data":{"id":"d4ee1hugws80","created":1727168235853,"text":"答案相关性 (Answer Relevancy)"},"children":[{"data":{"id":"d4eeasi4ty80","created":1727168964329,"text":"评估生成的答案 (answer) 与用户问题 (question) 之间相关程度"},"children":[]},{"data":{"id":"d4eeaswtjz40","created":1727168965217,"text":"为了计算这个分数，LLM会被提示多次为生成的答案生成适当的问题，并测量这些生成的问题与原始问题之间的平均余弦相似度。基本思想是，如果生成的答案准确地解决了最初的问题，LLM应该能够从答案中生成与原始问题相符的问题"},"children":[]}]},{"data":{"id":"d4ee1hzqf9s0","created":1727168236171,"text":"上下文精度 (Context Precision)"},"children":[{"data":{"id":"d4eecuvlk7s0","created":1727169126225,"text":"评估所有在上下文 (context) 中呈现的与基本事实 (ground-truth) 相关的条目是否排名较高"},"children":[]},{"data":{"id":"d4eecvbb79c0","created":1727169127175,"text":"理想情况下，所有相关文档块(chunks)必须出现在顶层"},"children":[]}]},{"data":{"id":"d4ee1i6ql0w0","created":1727168236595,"text":"上下文召回率 (Context Recall)"},"children":[{"data":{"id":"d4eefu0lpy80","created":1727169359444,"text":"衡量检索到的上下文 (context) 与人类提供的真实答案 (ground truth) 的一致程度"},"children":[]}]},{"data":{"id":"d4ee1ievhfk0","created":1727168237087,"text":"上下文相关性 (Context Relevancy)"},"children":[{"data":{"id":"d4eezvqtdsg0","created":1727170930489,"text":"衡量检索到的上下文 (context) 与用户问题 (question) 之间相关程度"},"children":[]}]}]}]},{"data":{"id":"d4efo5ur3vk0","created":1727172833235,"text":"优化","layout_mind_offset":{"x":460,"y":307},"expandState":"expand"},"children":[{"data":{"id":"d4f6a9vsfa00","created":1727247914874,"text":"分块","layout_right_offset":{"x":332,"y":459}},"children":[{"data":{"id":"d4efoehlq600","created":1727172852031,"text":"context 的质量往往取决于文档块的大小即 chunk_size, 当 chunk_size 较小时它与 question 的匹配度越高，但此时 context 的信息量就会相对较少，这样也会导致最终的 response 质量变差，而当 chunk_size 较大时虽然 context 的信息量较大，但是 context 与 question 的匹配度就会降低，这也会导致最终的 response 质量变差","layout_right_offset":{"x":2043,"y":8}},"children":[]},{"data":{"id":"d4efcu2l7340","created":1727171945581,"text":"LangChain","layout_mind_offset":{"x":58,"y":-186},"layout_right_offset":{"x":287,"y":33}},"children":[{"data":{"id":"d4effli166g0","created":1727172162016,"text":"父文档检索器","layout_right_offset":{"x":265,"y":-25}},"children":[{"data":{"id":"d4efg5ocozk0","created":1727172205934,"text":"检索完整文档","layout_right_offset":{"x":278,"y":-3}},"children":[]},{"data":{"id":"d4efg63sl140","created":1727172206868,"text":"检索较大的文档块","layout_right_offset":{"x":274,"y":11}},"children":[]}]}]},{"data":{"id":"d4efqedqw0w0","created":1727173008526,"text":"LlamaIndex","layout_mind_offset":{"x":-70,"y":-111},"layout_right_offset":{"x":329,"y":115}},"children":[{"data":{"id":"d4efw0clg940","created":1727173448166,"text":"从小到大的检索","layout_right_offset":{"x":336,"y":-27}},"children":[{"data":{"id":"d4efzlvhm000","created":1727173730113,"text":"在切割文档时同时设置多个不同的 chunk_size 的颗粒度","layout_right_offset":{"x":556,"y":-44}},"children":[]}]},{"data":{"id":"d4efy60zxmw0","created":1727173617254,"text":"窗口检索","layout_right_offset":{"x":316,"y":-15}},"children":[{"data":{"id":"d4eg0pa7qu00","created":1727173815898,"text":"首先将文档切割成更小的文档块, 当匹配到问题后，将该文档块周围的文档内容作为 context 输出","layout_right_offset":{"x":728,"y":-26}},"children":[]}]},{"data":{"id":"d4eg4sd0gv40","created":1727174136055,"text":"自动合并检索","layout_right_offset":{"x":332,"y":6}},"children":[{"data":{"id":"d4eg82qz5xk0","created":1727174393759,"text":"将文档按特定的层次结构进行切割","layout_right_offset":{"x":460,"y":-1}},"children":[]},{"data":{"id":"d4egcwir7vs0","created":1727174772022,"text":"一个父节点包含最多4个叶子节点(由文档层次结构确定)，那么如果父节点中有3个叶子节点被检索到，那么该父节点将会作为 context 被返回给 llm，而当只有1个叶子节点被检索到时，该父节点将不会被返回给 llm","layout_right_offset":{"x":1436,"y":41}},"children":[]}]}]}]},{"data":{"id":"d4f6tip1eoo0","created":1727249422976,"text":"索引","layout_right_offset":{"x":388,"y":650}},"children":[{"data":{"id":"d4f6tr3z6ow0","created":1727249441293,"text":"乘积量化  (Product Quantization)","layout_right_offset":{"x":388,"y":2}},"children":[]},{"data":{"id":"d4f6txu9pls0","created":1727249455944,"text":"倒排索引 (Inverted File Index)","layout_right_offset":{"x":362,"y":44}},"children":[]},{"data":{"id":"d4f6vknbvlk0","created":1727249583954,"text":"混合索引","layout_right_offset":{"x":255,"y":89}},"children":[{"data":{"id":"d4f724xcdy80","created":1727250098281,"text":"基于关键词的全文检索","layout_right_offset":{"x":328,"y":-18},"expandState":"expand"},"children":[{"data":{"id":"d4f6vqwb6lc0","created":1727249597558,"text":"BM25","layout_right_offset":{"x":278,"y":-27}},"children":[{"data":{"id":"d4f73zkv7eg0","created":1727250243370,"text":"词频 TF（Term Frequency），即一个词在一个文档中出现的频率越高，那么文档的相关性也越高","layout_right_offset":{"x":728,"y":-31}},"children":[]},{"data":{"id":"d4f746ex7t40","created":1727250258248,"text":"逆向文档频率 IDF（Inverse Document Frequency），即每个词在索引中出现的频率越高，相关性越低。IDF 主要是为了降低像“的” 这样高频词语的相关性，提升包含低频专业术语的文档的权重","layout_right_offset":{"x":1287,"y":10}},"children":[]},{"data":{"id":"d4f75bfcurc0","created":1727250347523,"text":"BM25 算法基于 TF-IDF 作了优化，主要是降低长文档的权重","layout_right_offset":{"x":561,"y":48}},"children":[]}]}]},{"data":{"id":"d4f72lz7imo0","created":1727250135398,"text":"向量语义相似度检索","layout_right_offset":{"x":315,"y":-1}},"children":[]}]}]},{"data":{"id":"d4f9g7bhksg0","created":1727256842807,"text":"多轮对话","layout_right_offset":{"x":413,"y":1123}},"children":[{"data":{"id":"d4f9j9f0yog0","created":1727257082467,"text":"问题指代了历史消息的某个重要对象（通常是问题的核心）时，就不能召回有用的知识，大模型的回答效果不会太好","layout_right_offset":{"x":872,"y":-44}},"children":[]},{"data":{"id":"d4f9p47utsw0","created":1727257541335,"text":"让大模型基于历史消息对用户最新的问题进行改写，补充指代对象，然后再去进行知识的召回，效果会大大改善","layout_right_offset":{"x":852,"y":9}},"children":[]},{"data":{"id":"d4f9xa7e80w0","created":1727258181281,"text":"多轮信息处理模块","layout_right_offset":{"x":351,"y":57}},"children":[]}]},{"data":{"id":"d4fa11pokdk0","created":1727258476252,"text":"重排序","layout_right_offset":{"x":432,"y":742}},"children":[{"data":{"id":"d4fa9om68gw0","created":1727259153019,"text":"Query generation","layout_right_offset":{"x":314,"y":-67}},"children":[]},{"data":{"id":"d4fa9siha3s0","created":1727259161503,"text":"Relevance generation","layout_right_offset":{"x":324,"y":-42}},"children":[]},{"data":{"id":"d4fa9t568rs0","created":1727259162875,"text":"Permutation generation","layout_right_offset":{"x":323,"y":-11}},"children":[{"data":{"id":"d4fad0ud59c0","created":1727259414729,"text":"sliding window strategy","layout_right_offset":{"x":428,"y":-20}},"children":[{"data":{"id":"d4fadghklb40","created":1727259448783,"text":"遵循冒泡排序思想的滑动窗口方法","layout_right_offset":{"x":472,"y":-34}},"children":[]}]}]}]},{"data":{"id":"d4f6cucq9cw0","created":1727248116162,"text":"查询","layout_right_offset":{"x":351,"y":-730}},"children":[{"data":{"id":"d4f5a8l81xc0","created":1727245090948,"text":"多重查询 (Multi Query)","layout_mind_offset":{"x":241,"y":29},"layout_right_offset":{"x":416,"y":-14}},"children":[{"data":{"id":"d4f5c6ffh1k0","created":1727245242972,"text":"当用户输入查询语句(自然语言)时，我们让大模型 (LLM) 基于用户的问题再生成多个查询语句，这些生成的查询语句是对用户查询语句的补充，它们是从不同的视角来补充用户的查询语句，然后每条查询语句都会从向量数据库中检索到一批相关文档，最后所有的相关文档都会被喂给 LLM，这样LLM就会生成比较完整和全面的答案。这样就可以避免因为查询语句的差异而导致结果不正确。","layout_right_offset":{"x":2345,"y":-63}},"children":[]}]},{"data":{"id":"d4f6m9ncwkg0","created":1727248854734,"text":"答案是基于用户自己书写的查询语句检索而来的，如果当用户没有正确书写查询语句，或者LLM不能够正确理解用户查询语句的含义时，此时LLM生成的答案可能就不够完整和全面","layout_right_offset":{"x":1208,"y":-216}},"children":[]},{"data":{"id":"d4f5q84mfrk0","created":1727246343771,"text":"RAG 融合 (Rag Fusion)","layout_mind_offset":{"x":720,"y":490},"layout_right_offset":{"x":372,"y":-4}},"children":[{"data":{"id":"d4f5ql8vjc80","created":1727246372326,"text":"在 Multi Query 的基础上，对其检索结果进行重新排序 (Reranking) 后输出 top k 个最相关文档，最后将这 top k 个文档喂给 LLM 并生成最终的答案 (answer)","layout_right_offset":{"x":1125,"y":-42}},"children":[]}]}]}]}]},"template":"default","theme":"fresh-blue","version":"1.4.33"}